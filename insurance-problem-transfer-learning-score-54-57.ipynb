{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-19T21:58:19.680755Z","iopub.execute_input":"2021-06-19T21:58:19.681073Z","iopub.status.idle":"2021-06-19T21:58:21.139194Z","shell.execute_reply.started":"2021-06-19T21:58:19.681001Z","shell.execute_reply":"2021-06-19T21:58:21.120279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading required packages","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics \nfrom sklearn import preprocessing\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nimport cv2\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.layers import Dense,GlobalAveragePooling2D\nfrom keras.applications import MobileNet\nfrom keras.applications.mobilenet import preprocess_input\nfrom keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2021-06-19T21:58:50.297957Z","iopub.execute_input":"2021-06-19T21:58:50.298301Z","iopub.status.idle":"2021-06-19T21:58:55.731273Z","shell.execute_reply.started":"2021-06-19T21:58:50.298269Z","shell.execute_reply":"2021-06-19T21:58:55.730384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading training data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/fast-furious-and-insured/Fast_Furious_Insured/train.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T21:59:04.285964Z","iopub.execute_input":"2021-06-19T21:59:04.286325Z","iopub.status.idle":"2021-06-19T21:59:04.325714Z","shell.execute_reply.started":"2021-06-19T21:59:04.286291Z","shell.execute_reply":"2021-06-19T21:59:04.324736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading testing data","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv('../input/fast-furious-and-insured/Fast_Furious_Insured/test.csv')\ndf_test","metadata":{"execution":{"iopub.status.busy":"2021-06-19T21:59:09.456438Z","iopub.execute_input":"2021-06-19T21:59:09.456768Z","iopub.status.idle":"2021-06-19T21:59:09.487075Z","shell.execute_reply.started":"2021-06-19T21:59:09.456738Z","shell.execute_reply":"2021-06-19T21:59:09.486218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pre-processing","metadata":{}},{"cell_type":"code","source":"# Get the number of missing data points per column\nmissing_values_count_train = df.isnull().sum()\nprint(missing_values_count_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T21:59:19.427579Z","iopub.execute_input":"2021-06-19T21:59:19.427903Z","iopub.status.idle":"2021-06-19T21:59:19.435027Z","shell.execute_reply.started":"2021-06-19T21:59:19.427873Z","shell.execute_reply":"2021-06-19T21:59:19.433852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the number of missing data points per column\nmissing_values_count_test = df_test.isnull().sum()\nprint(missing_values_count_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T21:59:30.126067Z","iopub.execute_input":"2021-06-19T21:59:30.126427Z","iopub.status.idle":"2021-06-19T21:59:30.133678Z","shell.execute_reply.started":"2021-06-19T21:59:30.126397Z","shell.execute_reply":"2021-06-19T21:59:30.132476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling missing values\ndf = df.fillna(method='bfill', axis=0).fillna(0)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T21:59:41.167668Z","iopub.execute_input":"2021-06-19T21:59:41.167983Z","iopub.status.idle":"2021-06-19T21:59:41.177857Z","shell.execute_reply.started":"2021-06-19T21:59:41.167953Z","shell.execute_reply":"2021-06-19T21:59:41.176968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking different values in Insurance company in the training set\ndf['Insurance_company'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T21:59:44.639431Z","iopub.execute_input":"2021-06-19T21:59:44.639747Z","iopub.status.idle":"2021-06-19T21:59:44.649607Z","shell.execute_reply.started":"2021-06-19T21:59:44.639717Z","shell.execute_reply":"2021-06-19T21:59:44.648524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking different values in Insurance company in the testing set\ndf_test['Insurance_company'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T22:00:01.49598Z","iopub.execute_input":"2021-06-19T22:00:01.496342Z","iopub.status.idle":"2021-06-19T22:00:01.647036Z","shell.execute_reply.started":"2021-06-19T22:00:01.496311Z","shell.execute_reply":"2021-06-19T22:00:01.645935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Label encoding and scaling","metadata":{}},{"cell_type":"code","source":"features_num = ['Cost_of_vehicle', 'Min_coverage', 'Max_coverage']\nfeatures_cat = ['Insurance_company']\n\nle= LabelEncoder()   \ndf['Insurance_company'] = le.fit_transform(df['Insurance_company'])\ndf_test['Insurance_company'] = le.transform(df_test['Insurance_company'])\n\npreprocessor = make_column_transformer(\n    (StandardScaler(), features_num),\n)\n\ny = df['Amount']\ntrain_imputed = df.loc[:,['Cost_of_vehicle', 'Min_coverage', 'Max_coverage', 'Insurance_company']]\nX = preprocessor.fit_transform(train_imputed)\n\ntest_imputed = df_test.loc[:,['Cost_of_vehicle', 'Min_coverage',  'Max_coverage', 'Insurance_company']]\ntest_X = preprocessor.transform(test_imputed)\n\ntrain_imputed.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-19T22:00:10.742529Z","iopub.execute_input":"2021-06-19T22:00:10.742854Z","iopub.status.idle":"2021-06-19T22:00:10.766458Z","shell.execute_reply.started":"2021-06-19T22:00:10.742824Z","shell.execute_reply":"2021-06-19T22:00:10.765516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train-test split\ntrain_X, val_X, train_y, val_y = train_test_split(X,y,random_state=1,test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T22:00:30.177648Z","iopub.execute_input":"2021-06-19T22:00:30.177964Z","iopub.status.idle":"2021-06-19T22:00:30.183978Z","shell.execute_reply.started":"2021-06-19T22:00:30.177935Z","shell.execute_reply":"2021-06-19T22:00:30.182857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train a random forest regressor","metadata":{}},{"cell_type":"code","source":"rf_model = RandomForestRegressor(random_state=1, n_estimators = 1000, max_depth=3)\n# fit your model\nrf_model.fit(train_X,train_y)\nval_preds = rf_model.predict(val_X)\n# Calculate the mean absolute error of your Random Forest model on the validation data\nrf_val_mae = mean_absolute_error(val_y,val_preds)\n\nprint(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))","metadata":{"execution":{"iopub.status.busy":"2021-06-19T22:00:33.107736Z","iopub.execute_input":"2021-06-19T22:00:33.108043Z","iopub.status.idle":"2021-06-19T22:00:34.840235Z","shell.execute_reply.started":"2021-06-19T22:00:33.108014Z","shell.execute_reply":"2021-06-19T22:00:34.839373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get the predictions for amount","metadata":{}},{"cell_type":"code","source":"amount_predictions = rf_model.predict(test_X)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T22:00:46.82696Z","iopub.execute_input":"2021-06-19T22:00:46.827285Z","iopub.status.idle":"2021-06-19T22:00:46.910372Z","shell.execute_reply.started":"2021-06-19T22:00:46.827257Z","shell.execute_reply":"2021-06-19T22:00:46.909522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare the images","metadata":{}},{"cell_type":"code","source":"X = df.loc[:,['Image_path']]\ny = df.loc[:,['Condition']]    \nX_test = df.loc[:,['Image_path']]\nprint('train set shape:', X.shape)\nprint('test set shape:', X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T22:00:50.722445Z","iopub.execute_input":"2021-06-19T22:00:50.72282Z","iopub.status.idle":"2021-06-19T22:00:50.733568Z","shell.execute_reply.started":"2021-06-19T22:00:50.722787Z","shell.execute_reply":"2021-06-19T22:00:50.732474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = []\nlabels = []\nfor (index_label, row_series) in df.iterrows():\n        img_path = row_series.values[0]\n        condition = row_series.values[-2]\n        labels.append(int(condition))\n        # load the image, pre-process it, and store it in the data list\n        originalImage = cv2.imread('/kaggle/input/fast-furious-and-insured/Fast_Furious_Insured/trainImages/' + img_path)\n        image = cv2.resize(originalImage, (224, 224))\n        image = img_to_array(image)\n        data.append(image)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T22:01:26.939317Z","iopub.execute_input":"2021-06-19T22:01:26.939641Z","iopub.status.idle":"2021-06-19T22:01:35.514804Z","shell.execute_reply.started":"2021-06-19T22:01:26.939613Z","shell.execute_reply":"2021-06-19T22:01:35.513967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transfer learning with MobileNet","metadata":{}},{"cell_type":"code","source":"base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\nx=base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(256,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\npreds=Dense(2,activation='softmax')(x) #final layer with softmax activation\nmodel=Model(inputs=base_model.input,outputs=preds)\n   # we want to set the first 20 layers of the network to be non-trainable\nfor layer in model.layers[:80]:\n    layer.trainable=False\nfor layer in model.layers[80:]:\n    layer.trainable=True","metadata":{"execution":{"iopub.status.busy":"2021-06-19T22:01:43.621624Z","iopub.execute_input":"2021-06-19T22:01:43.621931Z","iopub.status.idle":"2021-06-19T22:01:46.34924Z","shell.execute_reply.started":"2021-06-19T22:01:43.621902Z","shell.execute_reply":"2021-06-19T22:01:46.348418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import optimizers\n\nprint(len(data),len(labels))\ndata = np.array(data, dtype=\"float\")\nlabels = np.array(labels)\n    \n# partition the data into training and testing splits using 80% of\n# the data for training and the remaining 20% for testing\n(train_images, test_images, train_labels, test_labels) = train_test_split(data,labels, test_size=0.2, random_state=42)\n\n#(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n# Normalize pixel values to be between 0 and 1\ntrain_images, test_images = (train_images / 255.0)-0.5, (test_images / 255.0) -0.5\n\ntrain_labels = to_categorical(train_labels, 2)\ntest_labels = to_categorical(test_labels, 2)\n\n#compile and train the model\nadam=optimizers.Adam(\n                lr=0.002,\n                beta_1=0.9,\n                beta_2=0.999,\n                epsilon=None,\n                decay=0.0001,\n                amsgrad=False\n                )\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n#callback = callbacks.LearningRateScheduler(scheduler)\nhistory = model.fit(train_images, train_labels, batch_size=32,epochs=5,shuffle=True, validation_data=(test_images, test_labels))","metadata":{"execution":{"iopub.status.busy":"2021-06-19T22:02:05.417972Z","iopub.execute_input":"2021-06-19T22:02:05.418309Z","iopub.status.idle":"2021-06-19T22:02:20.847102Z","shell.execute_reply.started":"2021-06-19T22:02:05.418279Z","shell.execute_reply":"2021-06-19T22:02:20.846171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Getting the test prediction","metadata":{}},{"cell_type":"code","source":"condition_predictions = []\nfor (index_label, row_series) in df_test.iterrows():\n        img_path = row_series.values[0]\n        # load the image, pre-process it, and store it in the data list\n        originalImage = cv2.imread('/kaggle/input/fast-furious-and-insured/Fast_Furious_Insured/testImages/' + img_path)\n        image = cv2.resize(originalImage, (224, 224))\n        image = img_to_array(image)\n        image = image.reshape((1,224, 224, 3))\n        image = np.array(image, dtype=\"float\") / 255.0 - 0.5\n        prediction = model.predict(image)\n        prediction = prediction[0]\n        condition_predictions.append(np.argmax(prediction))\n       ","metadata":{"execution":{"iopub.status.busy":"2021-06-19T22:02:30.746531Z","iopub.execute_input":"2021-06-19T22:02:30.746862Z","iopub.status.idle":"2021-06-19T22:02:58.17982Z","shell.execute_reply.started":"2021-06-19T22:02:30.74683Z","shell.execute_reply":"2021-06-19T22:02:58.178922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing the submission","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({'Image_path': df_test.Image_path, 'Condition': condition_predictions, \n                          'Amount': amount_predictions})\nsubmission.to_csv('submission.csv', index=False)\nfrom IPython.display import FileLink\nFileLink('submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T22:11:29.372946Z","iopub.execute_input":"2021-06-19T22:11:29.373312Z","iopub.status.idle":"2021-06-19T22:11:29.387398Z","shell.execute_reply.started":"2021-06-19T22:11:29.373275Z","shell.execute_reply":"2021-06-19T22:11:29.38609Z"},"trusted":true},"execution_count":null,"outputs":[]}]}